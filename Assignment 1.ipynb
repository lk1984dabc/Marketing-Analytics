{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2fcce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec60785",
   "metadata": {},
   "source": [
    "## Early Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AB_test_data.csv\")\n",
    "df[\"purchase_TF\"] = df[\"purchase_TF\"] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eae7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we split the dataframe into two dataframes for two variants\n",
    "\n",
    "df_A = df[df[\"Variant\"] == \"A\"]\n",
    "df_B = df[df[\"Variant\"] == \"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c980cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 2020-08-30\n",
      "2020-08-01 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Check the date for both variants\n",
    "\n",
    "print(df_A[\"date\"].min(), df_A[\"date\"].max())\n",
    "print(df_B[\"date\"].min(), df_B[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c5e95",
   "metadata": {},
   "source": [
    "We have 13 months of Variant A data and 1 month of Variant B data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b0e54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if each id is unique\n",
    "\n",
    "len(df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c58306",
   "metadata": {},
   "source": [
    "If there are ids that are both in variant A and B groups, the assumption for two sample population would not be met.<br>\n",
    "<br>\n",
    "If there are duplicates, the 13-month Variant A data and 1-month Variant B data will not be independent and therefore we won't be able to use 13-month Variant A data but only 1-month Variant A data in two-sample t test. <br>\n",
    "If there aren't duplicates, the 13-month Variant A data and 1-month Variant B data will be independent and therefore we will be able to use 13-month Variant A data in two-sample t test. <br>\n",
    "<br>\n",
    "It turns out that each id here is unique, meaning that we can use all data in two-sample t test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca03eb7",
   "metadata": {},
   "source": [
    "## A/B test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257158b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample sizes for two variant groups are 5000,125000. Both are large enough.\n"
     ]
    }
   ],
   "source": [
    "n1 = len(df_B)\n",
    "n2 = len(df_A)\n",
    "print(\"The sample sizes for two variant groups are {},{}. Both are large enough.\".format(n1, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337944e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1hat = sum(df_B[\"purchase_TF\"])/len(df_B)\n",
    "p2hat = sum(df_A[\"purchase_TF\"])/len(df_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871c5c4",
   "metadata": {},
   "source": [
    "### Two sample t-test with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79dbd0d",
   "metadata": {},
   "source": [
    "Since assumptions of two-sample t test are met, we can conduct a two-sample t test using all data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7401b3b",
   "metadata": {},
   "source": [
    "Denote by p1, p2 the population conversion rate of Variant B and Variant A.<br>\n",
    "Our hypothesis test is: <br>\n",
    "<br>\n",
    "H0: p1 - p2 = 0 <br>\n",
    "Ha: p1 - p2 > 0 ,with a significant rate of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8138c8f",
   "metadata": {},
   "source": [
    "To calculate test statistic, we need to know the following parameters: <br>\n",
    "**p1hat**: Sample conversion rate of Variant B <br>\n",
    "**p2hat**: Sample conversion rate of Variant A <br>\n",
    "**pchat**: Combined estimate of population conversion rate <br>\n",
    "**n1**: Sample size of Variant B group <br>\n",
    "**n2**: Sample size of Variant A group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6419728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined estimate of population conversion rate is 0.15065384615384617.\n"
     ]
    }
   ],
   "source": [
    "# Calculate pchat\n",
    "\n",
    "pchat = (n1*p1hat + n2*p2hat)/(n1+n2)\n",
    "print(\"The combined estimate of population conversion rate is {}.\".format(pchat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ad3a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test statistic is 1013.8601308862007.\n"
     ]
    }
   ],
   "source": [
    "# Calculate test statistic\n",
    "\n",
    "z_score = (p1hat - p2hat)/(pchat*(1-pchat)*(1/n1 + 1/n2))\n",
    "print(\"The test statistic is {}.\".format(z_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1cf3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the p-value\n",
    "\n",
    "p_value = stats.norm.sf(abs(z_score))\n",
    "print(\"The p-value is {}.\".format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ea1c3",
   "metadata": {},
   "source": [
    "Since our p-value < 0.05, we reject our null hypothesis and conclude that Alternative B improved the conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31adf3",
   "metadata": {},
   "source": [
    "### Two sample t-test with 1-month data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848c11fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-01 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Get Variant A data in Auguest 2020\n",
    "\n",
    "date_caliper = \"2020-08-01\"\n",
    "df_Acut = df_A[df_A['date'] >= date_caliper]\n",
    "print(df_Acut[\"date\"].min(), df_Acut[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c225913",
   "metadata": {},
   "source": [
    "For comparison, we conduct a two-sample t test using only data in August 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db903c9b",
   "metadata": {},
   "source": [
    "Denote by p1, p2 the population conversion rate of Variant B and Variant A.<br>\n",
    "Our hypothesis test is: <br>\n",
    "<br>\n",
    "H0: p1 - p2 = 0 <br>\n",
    "Ha: p1 - p2 > 0 ,with a significant rate of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b49895",
   "metadata": {},
   "source": [
    "To calculate test statistic, we need to know the following parameters: <br>\n",
    "**p1hat**: Sample conversion rate of Variant B <br>\n",
    "**p2hat**: Sample conversion rate of Variant A <br>\n",
    "**pchat**: Combined estimate of population conversion rate <br>\n",
    "**n1**: Sample size of Variant B group <br>\n",
    "**n2**: Sample size of Variant A group <br>\n",
    "<br>\n",
    "In this test, **p1hat**, **n1** will be the same as the last test.<br>\n",
    "We shall focus on how different **p2hat** and **n2** affect the values of **pchat** and our **test statistic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32590de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample sizes for two variant groups are 5000,5000.\n"
     ]
    }
   ],
   "source": [
    "n1_2 = len(df_B)\n",
    "n2_2 = len(df_Acut)\n",
    "print(\"The sample sizes for two variant groups are {},{}.\".format(n1_2, n2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d5d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample conversion rate of 13-month data is 0.149616 while that of 1-month data is 0.1548.\n"
     ]
    }
   ],
   "source": [
    "p1hat_2 = sum(df_B[\"purchase_TF\"])/len(df_B)\n",
    "p2hat_2 = sum(df_Acut[\"purchase_TF\"])/len(df_Acut)\n",
    "print(\"The sample conversion rate of 13-month data is {} while that of 1-month data is {}.\".format(p2hat, p2hat_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db79454",
   "metadata": {},
   "source": [
    "We can see that **p2hat** we got with 1 month data is greater than the **p2hat** of 13 month data. <br>\n",
    "This might be due to the fact that 1-month data only captures information of Auguest while 13-month data captures the information of the whole year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b231ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined estimate of population conversion rate is 0.1657.\n",
      "Our estimate last time with 13-month data is 0.15065384615384617.\n"
     ]
    }
   ],
   "source": [
    "# Calculate pchat\n",
    "\n",
    "pchat_2 = (n1_2*p1hat_2 + n2_2*p2hat_2)/(n1_2+n2_2)\n",
    "print(\"The combined estimate of population conversion rate is {}.\".format(pchat_2))\n",
    "print(\"Our estimate last time with 13-month data is {}.\".format(pchat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0810d9",
   "metadata": {},
   "source": [
    "We can see that **pchat** we got this time is larger than last time.<br>\n",
    "<br>\n",
    "By breaking down the algorithm of pchat, we could easily find that the greatest effect came from a different **n2**.<br>\n",
    "The value of **n1** and **n2** determines the weight of **p1hat** and **p2hat** in calculating pchat. <br>\n",
    "In our last test with 13-month data, the weight of p1hat is **0.04**. <br>\n",
    "In our current test with 1-month data, the weight of p1hat is **0.5**. <br>\n",
    "<br>\n",
    "Therefore, we got a larget pchat this time, which will impact our test statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "984cf75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test statistic is 394.2318883541082.\n",
      "Our test statistic last time with 13-month data is 1013.8601308862007.\n"
     ]
    }
   ],
   "source": [
    "# Calculate test statistic\n",
    "\n",
    "z_score_2 = (p1hat_2 - p2hat_2)/(pchat_2*(1-pchat_2)*(1/n1_2 + 1/n2_2))\n",
    "print(\"The test statistic is {}.\".format(z_score_2))\n",
    "print(\"Our test statistic last time with 13-month data is {}.\".format(z_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed55895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the p-value\n",
    "\n",
    "p_value_2 = stats.norm.sf(abs(z_score_2))\n",
    "print(\"The p-value is {}.\".format(p_value_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45a080",
   "metadata": {},
   "source": [
    "Although p-value this time is still approximately 0 and rejects the null hypothesis. We need pay attention to the change in **z score**.<br>\n",
    "<br>\n",
    "In hypothesis tests, at a significant level of 0.05, we reject H0 if z score > 1.645. <br>\n",
    "In our last test with 13-month data, the z score is **1013.86**. <br>\n",
    "In our current test with 1-month data, the z score is **394.23**. <br>\n",
    "<br>\n",
    "We can see that, in this booking.com case, we are **more likely to reject H0** when using the 13-month data.<br>\n",
    "If one uses the 13-month data for testing, he/she will be more likely to conclude that Variant B improved conversion rates.<br>\n",
    "If one uses the 1-month data for testing, he/she will be more likely to conclude that Variant B didn't improve conversion rates.<br>\n",
    "<br>\n",
    "In this case, our conclusion didn't change. But this does indicate that **using different samples might lead to different test conclusions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cabc22",
   "metadata": {},
   "source": [
    "### One sample t-test with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d23ddd",
   "metadata": {},
   "source": [
    "Aside from using different samples to represent Variant A population in two-sample t tests, we also like to compare two-sample t test to one-sample t test.<br>\n",
    "<br>\n",
    "For one-sample t test, we assume that the population conversion rate of Variant B is the same as that of Variant A, i.e., our champion alternative.<br>\n",
    "Also, we notice that we don't need to check if two samples are independent since only one sample is used in one-sample t test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85cd53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our population conversion rate is 0.149616, which is also our conversion rate assumption for Alternative B.\n"
     ]
    }
   ],
   "source": [
    "p = sum(df_A[\"purchase_TF\"])/len(df_A)\n",
    "print(\"Our population conversion rate is {}, which is also our conversion rate assumption for Alternative B.\".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd89c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample size for Variant B groups is 5000.\n"
     ]
    }
   ],
   "source": [
    "n = len(df_B)\n",
    "print(\"The sample size for Variant B groups is {}.\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97598b1b",
   "metadata": {},
   "source": [
    "Denote by p the population conversion rate of Variant B.<br>\n",
    "Our hypothesis test is: <br>\n",
    "<br>\n",
    "H0: p = 0.1496 <br>\n",
    "Ha: p > 0.1496 ,with a significant rate of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e98e71",
   "metadata": {},
   "source": [
    "To calculate test statistic, we need to know the following parameters: <br>\n",
    "**phat**: Sample conversion rate of Variant B, **equals to p1hat** in two-sample t test <br>\n",
    "**p**: Assumed population conversion rate of Variance B, **equals to p2hat** in two-sample t test <br>\n",
    "**n**: Sample size of Variant B group, **equals to n1** in two-sample t test <br>\n",
    "Less parameters are needed for one-sample t test than two-sample t test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cdf5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample conversion rate of Variant B is 0.1766.\n"
     ]
    }
   ],
   "source": [
    "phat = sum(df_B[\"purchase_TF\"])/len(df_B)\n",
    "print(\"The sample conversion rate of Variant B is {}.\".format(phat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a881e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test statistic is 1060.4329470067144.\n",
      "The test statistic of the two-sample t test is 1013.8601308862007.\n"
     ]
    }
   ],
   "source": [
    "# Calculate test statistic\n",
    "\n",
    "z_score_1 = (phat - p)/(p*(1-p)/n)\n",
    "print(\"The test statistic is {}.\".format(z_score_1))\n",
    "print(\"The test statistic of the two-sample t test is {}.\".format(z_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2e362",
   "metadata": {},
   "source": [
    "The test statistic of the one-sample t test is greater than that of the two-sample t test.<br>\n",
    "<br>\n",
    "The z score function in two-sample t test is (p1hat - p2hat)/(pchat$*$(1-pchat)(1/n1 + 1/n2)).<br>\n",
    "The z score function in one-sample t test with equivalent parameters is (p1hat - p2hat)/(p2hat$*$(1-p2hat)/n1).<br>\n",
    "We can see that two z score functions are very similar.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf99042",
   "metadata": {},
   "source": [
    "**Given that the test statistic of one-sample and two-sample tests are also very close and one-sample t test needs less parameters, we wonder if, under certain situations, two-sample t test is equivalent to one-sample t test.**<br>\n",
    "<br>\n",
    "There is no difference in the numerator part.<br>\n",
    "In the demonimator part, pchat = 0.04$*$p1hat + 0.96$*$p2hat, and the weights of p1hat and p2hat are determined by sample sizes n1, n2.<br>\n",
    "Also, as n2 approaches infinity, (1/n1 + 1/n2) approaches 1/n1.<br>\n",
    "<br>\n",
    "From comparisons above, we can see that the sample sizes n1 and n2 are the influencers of the two-sample t test.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4094413",
   "metadata": {},
   "source": [
    "And this leads to our conclusions:<br>\n",
    "<br>\n",
    "**When the control group sample size n2 is much greater than the treatment group sample size n1, i.e., n2 >> n1, two-sample t test could be considered as equivalent to one-sample t test.**<br>\n",
    "<br>\n",
    "**Vice versa, when n2 is not much greater than n1, one-sample t test should not be used as a replacement of two-sample t test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0309afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the p-value\n",
    "\n",
    "p_value_1 = stats.norm.sf(abs(z_score_1))\n",
    "print(\"The p-value is {}.\".format(p_value_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d560d",
   "metadata": {},
   "source": [
    "In conclusion to A/B test, all our hypothesis tests come to the conclusion that **Alternative B improved conversion rates over Alternative A**.<br>\n",
    "Moreover, given our comparisons between hypothesis tests, **one-sample t test is optimal test** for the *booking.com* case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd2624",
   "metadata": {},
   "source": [
    "## Solving for Optimal Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c58b41",
   "metadata": {},
   "source": [
    "Since we use one-sided one-sample t test, we use a different optimizal sample size estimation algorithm.\n",
    "\n",
    "n* = $(t\\alpha + t\\beta)^2$$p(1-p)\\over\\delta^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa0d1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_alpha = stats.norm.ppf(0.95)\n",
    "t_beta = stats.norm.ppf(0.8)\n",
    "p = sum(df_A[\"purchase_TF\"])/len(df_A)\n",
    "delta = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2b94f",
   "metadata": {},
   "source": [
    "Using all Variant A data as our prior knowledge, we have the estimate conversion rate p = 0.1496.<br>\n",
    "Also, let's assume we want our test to accurately detect the improvement when the true improvement $\\delta$ = 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1439b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal sample size for a one-sided one-sample test with significant rate of 0.95 and a power of 0.2 is 315.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the optimal sample size\n",
    "\n",
    "nstar = round((t_alpha + t_beta)**2*p*(1-p)/delta**2)\n",
    "print(\"The optimal sample size for a one-sided one-sample test with significant rate of 0.95 and a power of 0.2 is {}.\".format(nstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac9ea072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function that automatically conduct hypothesis test with one random sample.\n",
    "\n",
    "def sample_test(n, tstar, estimate):\n",
    "    \n",
    "    '''\n",
    "    The input is the sample size, t statistic at significant level, and estimate for the null hypothesis.\n",
    "    The output is the test statistic and whether the null hypothesis is rejected.\n",
    "    '''\n",
    "\n",
    "    df_sample = df_B.sample(n = n)\n",
    "    p = estimate\n",
    "    phat = sum(df_sample[\"purchase_TF\"])/nstar\n",
    "    z = (phat-p)/(p*(1-p)/nstar)\n",
    "    \n",
    "    if abs(z) >= tstar:\n",
    "        rejection = True\n",
    "    else:\n",
    "        rejection = False\n",
    "    \n",
    "    return z, rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c6b9e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z score</th>\n",
       "      <th>Reject H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.302380</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.003798</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.302380</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.705215</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187.618978</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.705215</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.162096</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.003798</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.003798</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.845499</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Z score  Reject H0\n",
       "0   93.302380       True\n",
       "1   54.003798       True\n",
       "2   93.302380       True\n",
       "3   14.705215       True\n",
       "4  187.618978       True\n",
       "5   14.705215       True\n",
       "6  101.162096       True\n",
       "7   54.003798       True\n",
       "8   54.003798       True\n",
       "9    6.845499       True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct the test 10 times and report the result\n",
    "\n",
    "test_result = [sample_test(nstar,t_alpha,p) for i in range(10)]\n",
    "df_10test = pd.DataFrame(test_result, columns = [\"Z score\", \"Reject H0\"])\n",
    "df_10test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19b83406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     97\n",
       "False     3\n",
       "Name: Reject H0, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the test 100 times and report the result\n",
    "\n",
    "test_result = [sample_test(n,t_alpha,p) for i in range(100)]\n",
    "df_100test = pd.DataFrame(test_result, columns = [\"Z score\", \"Reject H0\"])\n",
    "df_100test[\"Reject H0\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2b57a",
   "metadata": {},
   "source": [
    "Among the 10 tests in our first trial, all 10 tests rejected H0.<br>\n",
    "Among the 100 tests in our second trial, 97 tests rejected H0 and 3 tests failed to reject H0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc9ca33",
   "metadata": {},
   "source": [
    "## Sequential Probability Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfc7c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the function so that it returns the sample\n",
    "\n",
    "def sample_test2(n, tstar, estimate):\n",
    "    \n",
    "    '''\n",
    "    The input is the sample size, t statistic at significant level, and estimate for the null hypothesis.\n",
    "    The output is the test statistic and whether the null hypothesis is rejected.\n",
    "    '''\n",
    "\n",
    "    df_sample = df_B.sample(n = n)\n",
    "    p = estimate\n",
    "    phat = sum(df_sample[\"purchase_TF\"])/nstar\n",
    "    z = (phat-p)/(p*(1-p)/nstar)\n",
    "    \n",
    "    if abs(z) >= tstar:\n",
    "        rejection = True\n",
    "    else:\n",
    "        rejection = False\n",
    "    \n",
    "    return z, rejection, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca22c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun 10 samples and store the samples\n",
    "\n",
    "z_list = []\n",
    "rejection_list = []\n",
    "df_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    z, rejection, sample = sample_test2(nstar,t_alpha,p)\n",
    "    z_list.append(z)\n",
    "    rejection_list.append(rejection)\n",
    "    df_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7564a2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z score</th>\n",
       "      <th>Rejection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.899545</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.564932</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.705215</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.039828</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.014218</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.582947</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85.442663</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.284365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61.863514</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-8.873934</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Z score  Rejection\n",
       "0  171.899545       True\n",
       "1   22.564932       True\n",
       "2   14.705215       True\n",
       "3  164.039828       True\n",
       "4   -1.014218      False\n",
       "5   77.582947       True\n",
       "6   85.442663       True\n",
       "7   38.284365       True\n",
       "8   61.863514       True\n",
       "9   -8.873934       True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the test results of the 10 samples\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test[\"Z score\"] = z_list\n",
    "df_test[\"Rejection\"] = rejection_list\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b766a",
   "metadata": {},
   "source": [
    "Our hypothesis test for SQRT is: <br>\n",
    "<br>\n",
    "H0: p = 0.1496 <br>\n",
    "Ha: p = 0.18 ,with a significant rate of 0.05 and power of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b681b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated conversion rate of our null hypothesis is 0.149616 and that of our alternative hypothesis is 0.18.\n"
     ]
    }
   ],
   "source": [
    "p0 = p\n",
    "p1 = 0.18\n",
    "print(\"The estimated conversion rate of our null hypothesis is {} and that of our alternative hypothesis is {}.\".format(p0, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e3c6ec1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each observation of conversion will change the log-likelihood by 0.18488483919711945.\n",
      "Each observation of non conversion will change the log-likelihood by -0.03638367191699427.\n"
     ]
    }
   ],
   "source": [
    "# Calculate log-likelihood changes for each new observation\n",
    "\n",
    "log_pos = np.log(p1/p0)\n",
    "log_neg = np.log((1-p1)/(1-p0))\n",
    "print(\"Each observation of conversion will change the log-likelihood by {}.\\nEach observation of non conversion will change the log-likelihood by {}.\".format(log_pos, log_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b880e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We fail to reject H0 when log-likelihood is greater than 2.772588722239781.\n",
      "We reject H0 when log-likelihood is smaller than -1.5581446180465497.\n"
     ]
    }
   ],
   "source": [
    "# Calculate Wald boundaries\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "a_upper = np.log((1-beta)/alpha)\n",
    "b_lower = np.log(beta/(1-alpha))\n",
    "print(\"We fail to reject H0 when log-likelihood is greater than {}.\\nWe reject H0 when log-likelihood is smaller than {}.\".format(a_upper, b_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b13ed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function that performs SQRT on our sample\n",
    "\n",
    "def sqrt_test(df, upper, lower):\n",
    "    \n",
    "    '''\n",
    "    The input of the function is one sample dataframe, the upper bound, and the lower bound for the test.\n",
    "    The output of the function is the number of observation that stops the test, test result, and log-likelihood value.\n",
    "    '''\n",
    "    \n",
    "    conversion = df.reset_index()[\"purchase_TF\"]\n",
    "    log_lik = 0\n",
    "    num = len(conversion)\n",
    "    rejection = None\n",
    "    \n",
    "    for i in range(len(conversion)):\n",
    "        if conversion[i] == 1:\n",
    "            log_lik += log_pos\n",
    "        elif conversion[i] == 0:\n",
    "            log_lik += log_neg\n",
    "        if log_lik >= upper:\n",
    "            num = i+1\n",
    "            rejection = True\n",
    "            break\n",
    "        elif log_lik <= lower:\n",
    "            num = i+1\n",
    "            rejection = False\n",
    "            break\n",
    "        \n",
    "    return num, rejection, log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e9eddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>reject H0</th>\n",
       "      <th>log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>True</td>\n",
       "      <td>2.773881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.397431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.618700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>True</td>\n",
       "      <td>2.910517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.559351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>1.151448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>1.372717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>0.045106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>0.708911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.593554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter reject H0  log-likelihood\n",
       "0   240      True        2.773881\n",
       "1   315      None       -0.397431\n",
       "2   315      None       -0.618700\n",
       "3   218      True        2.910517\n",
       "4   128     False       -1.559351\n",
       "5   315      None        1.151448\n",
       "6   315      None        1.372717\n",
       "7   315      None        0.045106\n",
       "8   315      None        0.708911\n",
       "9   208     False       -1.593554"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sqrt10 = pd.DataFrame([sqrt_test(df) for df in df_list], columns = [\"iter\", \"reject H0\",\"log-likelihood\"])\n",
    "df_sqrt10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9858e405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average iteration number, including those that didn't come to conclusions, is 268.4.\n"
     ]
    }
   ],
   "source": [
    "avg_iter10 = df_sqrt10[\"iter\"].mean()\n",
    "print(\"The average iteration number, including those that didn't come to conclusions, is {}.\".format(avg_iter10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0e56f",
   "metadata": {},
   "source": [
    "Among the 10 samples we had, only 4 of them stopped the test prior to using the full sample.<br>\n",
    "It seems that we needed more samples for sequential probability ratio test than one-sample t test.<br>\n",
    "Unlike one-sample t tests, our available SQRTs are not consistent in results: 2 rejected H0 and 2 failed to reject H0.<br>\n",
    "<br>\n",
    "I think that the result of SQRT is largely affected by my choice of alternative proportion.<br>\n",
    "Proportion closer to the null should need larger sample than proportion far from the null."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
